# Deep Reinforcement Learning Model For Visual Search
When people search for a target in a novel image they often make use of eye movements to bring the relatively high acuity fovea to
bear on areas of interest. The strategies that control these eye movements for visual search have been of substantial scientific
interest. In this project we presented a new computational model that shows how strategies for visual search are an emergent
consequence of perceptual/motor constraints and approximately optimal strategies. The model solves a Partially Observable Markov
Decision Process (POMDP) using deep Q-learning to acquire strategies that optimise the tradeoff between speed and accuracy.

## Model Architecture
<table>
  <tr>
    <td><img src="/architecture.jpg?raw=true"></td>
  </tr>
</table>

## Demo
Open test.hml for demo.
